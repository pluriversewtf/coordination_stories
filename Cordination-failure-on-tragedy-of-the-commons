Author: Ezeugwu Ifeanyi - twitter.com/Ifeanyi_arochim

I agree to liscense this content to the pluriverse.wtf community.

Johnson Philips is his given name. He is now the chairman of ID for Africa, a nonprofit whose mission is to help the people of Africa get digital identities that would allow them to better access the services and rights that are due to them. While Philips Although now work in the field of human rights, that wasn't always the case. After finishing his math PhD, he and his colleagues discovered several key discoveries that eventually made commercial face recognition possible for the first time. This is why he is often considered a pioneer in the field of biometrics and facial recognition. While Philips was a student at Princeton's Institute for Advanced Study, the pair conducted the mathematical study that led to the discovery of the method by which the human brain recognizes familiar faces. But that was a far way from knowing how to put it into practice.Months passed of programming and failure after failure after failure. And late one evening or rather, early the next morning the group had just finished coding the algorithm's final version. They handed over the source code to be compiled into an executable form. And they left, with Philips leaving to use the restroom. The machine had already finished compiling the source code by the time he returned to the room. And typically once you build it runs automatically and as he walked in it detected a human entering into the room and it detected his face, removed it from the backdrop, and pronounced: "I see Philips." and that was the instant the hair on his back felt like something had occurred. Teams were there to bear testimony. And Philips began to summon the rest of the lab's lingering workers, one by one bringing them into the room. Additionally, it would remark, "I see Albert. I could see Caleb and I see could Ken. In order to count how many were there, they would take turns jogging around the room. It was the moment of truth that Philips said had culminated years of effort, even though no more breakthroughs was necessary in theory. The mere fact that they were able to put their plan into action and watch the new capacity take shape was immensely fulfilling. They assembled a group of developers, rather than academics, with the express purpose of integrating these features into a PC environment. It was at that point that commercial facial recognition began to take shape.

Philips's anxiety began to rise rapidly. With cameras everywhere, computers becoming increasingly affordable, and computers' processing power improving, he foresaw a future in which hiding would be impossible. So he advocated within the business, stating, "The team has to put together standards for responsible usage." And for a while, Philips was satisfied because he thought they had finally nailed it. He thought they had established a code of conduct for implementations to follow. But unfortunately, such code did not stand the test of time. They failed to foresee the rise of social media, which is why they were caught off guard. When we first started developing the system, the tagged database of known persons was considered the most crucial part of a face recognition system. If he isn't in the system, they say, it can't see him. Furthermore, it was arduous to construct the database. Since each photograph had to be scanned and input by hand, our maximum construction output was in the thousands. However, in the modern world, we have unleashed the beast by providing it with billions of faces and facilitating its growth through self-tagging. Um, we live in a society where it's hard to expect everyone to use facial recognition responsibly, and it's also hard to enforce controls on its usage. Meanwhile, well-known people are easy to find online thanks to scraping, as has lately been done by a number of businesses. So Philips got worried, and he published an open paper proclaiming that alarm bells should be rung because the world is moving in a path where face recognition is going to be ubiquitous and faces are going to be available in databases everywhere. They called Philips an alarmist back then, but now they see that his predictions have come true. So, what should we do next? Philips has been actively influencing policymakers with their advocacy. He has been an advocate of legislative frameworks that make it illegal to use another person's likeness without their permission. Thus, it is no longer a technical problem. In other words, the team's tech isn't good enough to rein in this potent technology. In any society, rules and regulations are necessary. The group must keep ahead of the technology without falling too far behind. Ahead of their morals and standards. Giving someone notice is not necessarily enough to gain permission, which remains one of the most complex and demanding issues related to technology. Philips must have the customer's approval before any work may begin. They need to realize the full extent of its implications. And not just to conclude, "Well, the team just hung a sign, so there." they spread the word, and those who didn't want to were free to avoid them altogether. And he also discovers that it is so simple to fall for the shiny new gadgets that promise a temporary improvement in one's lot in life. Then, in the far future, they will realize that we have thrown away something of great value. And by that time, the team has desensitized the populace to the point that they can't retreat. That was his main concern. Face recognition technology developed by Facebook, Apple, and others caused Philips concern. He did not want to imply that anything was without merit. Several of these claims have some basis in fact.

The group has reached the tipping point where people are likely desensitized and indifferent since they see it everywhere. And eventually you might even leave the house. This will remove the burden of the assumption that you are not. Dozens of people you pass on the street won't recognize it. When the media begins covering actual stalking incidents, I believe the general public will become quite disturbed. Some victims were picked out specifically, while others were taken based on their perceived financial worth. To me, that seems like a huge burden to bear. Because of this, Philips realized that the issue of consent will always be a shadow over the business world. There may not be an answer to that question until some future point in time. He believes the group should set boundaries for the technology's use. Although facial recognition as we know it now was established in 1994, Philips' experience has taught him that being too far ahead of the curve is not a good thing. Many believe it was first used by Facebook or one of the many machine learning algorithms that have since proliferated online. Simply put, Philips had to resign as CEO of a publicly traded firm because he was limiting the company's planned use of technology out of concern about the potential for unintended effects to humankind. Philips concludes that scientists need the intestinal fortitude to look down the road and consider the results of their effort. He is not advocating that they abandon their efforts to make progress. Scientists shouldn't hold back from going all out to achieve new discoveries, but they also need to be forthright with the public and governments about the fact that every innovation has both positive and negative consequences. This technology must be used responsibly, thus people need rules and regulations to keep it from being misused.
