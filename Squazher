A coordination failure is a class of problems where all participants would be better off if they cooperate, but without a trustworthy framework to coordinate their actions, each individual follows their rational self-interest, leading everyone to an outcome where everybody is worse off. Coordination failure is one useful lens to view the interlocking crises we face in modern societies. For example, climate change would be easier to deal with if everyone could agree to take simultaneous action to reduce carbon-intensive activity. But without that agreement, it’s in everyone’s short term self-interest to keep polluting. So this is one of the reasons for the utopian optimism in web3: perhaps this new technology can help us to solve the global coordination failures that have us racing towards a grim future. The hope is that maybe we can invent a new class of virtual institutions that more effectively encode our values into our economic & legal systems. These institutions will be better able to solve coordination failures because they’re more trustworthy, governed by transparent, programmatically-enforced rules instead of corruptible officials. And they’re global-by-default, not limited to artificial nationstate boundaries.
There are impersonal, structural forces underlying everything, from evolution to capitalist markets. If “in some competition optimizing for X, the opportunity arises to throw some other value under the bus for improved X", everyone has an incentive to do so. This does not change the relative status of participants, but everyone’s absolute status worsens. This is rational for each individual in isolation, but are disastrous for the community of individuals. Coordination problems are keeping us from choosing the obviously better solutions. Excess resources, physical limitations and a weak link with human values keep these optimisation processes somewhat in check for now, but technology will likely increase their effectiveness and allow them to take over everything, crowding us and our interests out in the process. We need some form of coordination, some form of institutional oversight to keep human values in play, and - at some point - to even allow for survival. But the coordination problem is inescapable: To coordinate and change the system, we need incentives to coordinate and change the system. As long as the incentive structures encourage sacrificing human values for powers, this will be done. We need to destroy the structures making this tradeoff possible.
Why does Moloch frighten me so much?  Because it’s not an evil corporation or a villainous leader— it’s the very nature of optimisation processes, left unchecked.  Whenever we create competition, or have an incentive structure that promotes individual behaviour vior, we see these kinds of unfair situations arise.  It’s not something in our world; it’s how our world works. Coordinating this, however, is often logistically challenging (or people may double-cross one another).  So we will often turn to agents that are outside of our system, like arbiters or governments, which have different incentives than us individuals.  Or we impose group punishments on those who try to double-cross the rest of us, which usually takes the form of laws. Still, as we’ve seen with far too many governments, Moloch is still alive and kicking; it’s too easy to get trapped into these traps.  We can still do better. Conquering Moloch is an endeavour that brings together game theory, politics, ethics, and optimisation.   I see it as the embodiment of the challenge of our times— that which we fight, after we’ve resolved all of our own personal disagreements.
